{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "from jax import random\n",
    "import wandb\n",
    "\n",
    "from src.models import make_PoN_Ens_loss as make_loss\n",
    "import src.data\n",
    "from src.data import NumpyLoader\n",
    "from src.utils.training import setup_training, train_loop\n",
    "from experiments.configs.toy_pon_ens import get_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['XLA_FLAGS'] = \"--xla_gpu_force_compilation_parallelism=1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'train_pon_ens.ipynb'\n",
    "# ^ W&B doesn't know how to handle VS Code notebooks.\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_fn = getattr(src.data, config.dataset_name)\n",
    "train_dataset, test_dataset, val_dataset = data_gen_fn(**config.dataset.to_dict())\n",
    "train_loader = NumpyLoader(train_dataset, config.batch_size)\n",
    "val_loader = NumpyLoader(val_dataset, config.batch_size)\n",
    "test_loader = NumpyLoader(test_dataset, config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+------------+--------+-----------+--------+\n",
      "| Name                                        | Shape      | Size   | Mean      | Std    |\n",
      "+---------------------------------------------+------------+--------+-----------+--------+\n",
      "| batch_stats/nets_0/layer_0/BatchNorm_0/mean | (100,)     | 100    | 0.0       | 0.0    |\n",
      "| batch_stats/nets_0/layer_0/BatchNorm_0/var  | (100,)     | 100    | 1.0       | 0.0    |\n",
      "| batch_stats/nets_0/layer_1/BatchNorm_0/mean | (100,)     | 100    | 0.0       | 0.0    |\n",
      "| batch_stats/nets_0/layer_1/BatchNorm_0/var  | (100,)     | 100    | 1.0       | 0.0    |\n",
      "| batch_stats/nets_1/layer_0/BatchNorm_0/mean | (100,)     | 100    | 0.0       | 0.0    |\n",
      "| batch_stats/nets_1/layer_0/BatchNorm_0/var  | (100,)     | 100    | 1.0       | 0.0    |\n",
      "| batch_stats/nets_1/layer_1/BatchNorm_0/mean | (100,)     | 100    | 0.0       | 0.0    |\n",
      "| batch_stats/nets_1/layer_1/BatchNorm_0/var  | (100,)     | 100    | 1.0       | 0.0    |\n",
      "| batch_stats/nets_2/layer_0/BatchNorm_0/mean | (100,)     | 100    | 0.0       | 0.0    |\n",
      "| batch_stats/nets_2/layer_0/BatchNorm_0/var  | (100,)     | 100    | 1.0       | 0.0    |\n",
      "| batch_stats/nets_2/layer_1/BatchNorm_0/mean | (100,)     | 100    | 0.0       | 0.0    |\n",
      "| batch_stats/nets_2/layer_1/BatchNorm_0/var  | (100,)     | 100    | 1.0       | 0.0    |\n",
      "| batch_stats/nets_3/layer_0/BatchNorm_0/mean | (100,)     | 100    | 0.0       | 0.0    |\n",
      "| batch_stats/nets_3/layer_0/BatchNorm_0/var  | (100,)     | 100    | 1.0       | 0.0    |\n",
      "| batch_stats/nets_3/layer_1/BatchNorm_0/mean | (100,)     | 100    | 0.0       | 0.0    |\n",
      "| batch_stats/nets_3/layer_1/BatchNorm_0/var  | (100,)     | 100    | 1.0       | 0.0    |\n",
      "| batch_stats/nets_4/layer_0/BatchNorm_0/mean | (100,)     | 100    | 0.0       | 0.0    |\n",
      "| batch_stats/nets_4/layer_0/BatchNorm_0/var  | (100,)     | 100    | 1.0       | 0.0    |\n",
      "| batch_stats/nets_4/layer_1/BatchNorm_0/mean | (100,)     | 100    | 0.0       | 0.0    |\n",
      "| batch_stats/nets_4/layer_1/BatchNorm_0/var  | (100,)     | 100    | 1.0       | 0.0    |\n",
      "| params/logscale                             | (1,)       | 1      | 0.0       | 0.0    |\n",
      "| params/nets_0/input_layer/bias              | (100,)     | 100    | -0.0436   | 0.605  |\n",
      "| params/nets_0/input_layer/kernel            | (1, 100)   | 100    | -0.115    | 0.52   |\n",
      "| params/nets_0/layer_0/BatchNorm_0/bias      | (100,)     | 100    | 0.0       | 0.0    |\n",
      "| params/nets_0/layer_0/BatchNorm_0/scale     | (100,)     | 100    | 1.0       | 0.0    |\n",
      "| params/nets_0/layer_0/Dense_0/bias          | (100,)     | 100    | -0.0726   | 0.619  |\n",
      "| params/nets_0/layer_0/Dense_0/kernel        | (100, 100) | 10,000 | 0.000147  | 0.0575 |\n",
      "| params/nets_0/layer_1/BatchNorm_0/bias      | (100,)     | 100    | 0.0       | 0.0    |\n",
      "| params/nets_0/layer_1/BatchNorm_0/scale     | (100,)     | 100    | 1.0       | 0.0    |\n",
      "| params/nets_0/layer_1/Dense_0/bias          | (100,)     | 100    | -0.0269   | 0.603  |\n",
      "| params/nets_0/layer_1/Dense_0/kernel        | (100, 100) | 10,000 | -0.000511 | 0.0575 |\n",
      "| params/nets_0/output_layer/bias             | (1,)       | 1      | -0.443    | 0.0    |\n",
      "| params/nets_0/output_layer/kernel           | (100, 1)   | 100    | 0.0033    | 0.0572 |\n",
      "| params/nets_1/input_layer/bias              | (100,)     | 100    | 0.106     | 0.544  |\n",
      "| params/nets_1/input_layer/kernel            | (1, 100)   | 100    | 0.0259    | 0.607  |\n",
      "| params/nets_1/layer_0/BatchNorm_0/bias      | (100,)     | 100    | 0.0       | 0.0    |\n",
      "| params/nets_1/layer_0/BatchNorm_0/scale     | (100,)     | 100    | 1.0       | 0.0    |\n",
      "| params/nets_1/layer_0/Dense_0/bias          | (100,)     | 100    | 0.0703    | 0.582  |\n",
      "| params/nets_1/layer_0/Dense_0/kernel        | (100, 100) | 10,000 | 0.000123  | 0.0575 |\n",
      "| params/nets_1/layer_1/BatchNorm_0/bias      | (100,)     | 100    | 0.0       | 0.0    |\n",
      "| params/nets_1/layer_1/BatchNorm_0/scale     | (100,)     | 100    | 1.0       | 0.0    |\n",
      "| params/nets_1/layer_1/Dense_0/bias          | (100,)     | 100    | -0.12     | 0.587  |\n",
      "| params/nets_1/layer_1/Dense_0/kernel        | (100, 100) | 10,000 | 0.000546  | 0.0575 |\n",
      "| params/nets_1/output_layer/bias             | (1,)       | 1      | 0.132     | 0.0    |\n",
      "| params/nets_1/output_layer/kernel           | (100, 1)   | 100    | 0.00177   | 0.0601 |\n",
      "| params/nets_2/input_layer/bias              | (100,)     | 100    | 0.0861    | 0.577  |\n",
      "| params/nets_2/input_layer/kernel            | (1, 100)   | 100    | -0.0367   | 0.549  |\n",
      "| params/nets_2/layer_0/BatchNorm_0/bias      | (100,)     | 100    | 0.0       | 0.0    |\n",
      "| params/nets_2/layer_0/BatchNorm_0/scale     | (100,)     | 100    | 1.0       | 0.0    |\n",
      "| params/nets_2/layer_0/Dense_0/bias          | (100,)     | 100    | 0.0773    | 0.578  |\n",
      "| params/nets_2/layer_0/Dense_0/kernel        | (100, 100) | 10,000 | -0.000543 | 0.0579 |\n",
      "| params/nets_2/layer_1/BatchNorm_0/bias      | (100,)     | 100    | 0.0       | 0.0    |\n",
      "| params/nets_2/layer_1/BatchNorm_0/scale     | (100,)     | 100    | 1.0       | 0.0    |\n",
      "| params/nets_2/layer_1/Dense_0/bias          | (100,)     | 100    | 0.112     | 0.576  |\n",
      "| params/nets_2/layer_1/Dense_0/kernel        | (100, 100) | 10,000 | -0.000392 | 0.0576 |\n",
      "| params/nets_2/output_layer/bias             | (1,)       | 1      | 0.882     | 0.0    |\n",
      "| params/nets_2/output_layer/kernel           | (100, 1)   | 100    | -0.0131   | 0.0575 |\n",
      "| params/nets_3/input_layer/bias              | (100,)     | 100    | -0.0255   | 0.609  |\n",
      "| params/nets_3/input_layer/kernel            | (1, 100)   | 100    | -0.0764   | 0.575  |\n",
      "| params/nets_3/layer_0/BatchNorm_0/bias      | (100,)     | 100    | 0.0       | 0.0    |\n",
      "| params/nets_3/layer_0/BatchNorm_0/scale     | (100,)     | 100    | 1.0       | 0.0    |\n",
      "| params/nets_3/layer_0/Dense_0/bias          | (100,)     | 100    | -0.0437   | 0.576  |\n",
      "| params/nets_3/layer_0/Dense_0/kernel        | (100, 100) | 10,000 | 0.000384  | 0.0577 |\n",
      "| params/nets_3/layer_1/BatchNorm_0/bias      | (100,)     | 100    | 0.0       | 0.0    |\n",
      "| params/nets_3/layer_1/BatchNorm_0/scale     | (100,)     | 100    | 1.0       | 0.0    |\n",
      "| params/nets_3/layer_1/Dense_0/bias          | (100,)     | 100    | 0.0771    | 0.589  |\n",
      "| params/nets_3/layer_1/Dense_0/kernel        | (100, 100) | 10,000 | 0.000774  | 0.0572 |\n",
      "| params/nets_3/output_layer/bias             | (1,)       | 1      | -0.0751   | 0.0    |\n",
      "| params/nets_3/output_layer/kernel           | (100, 1)   | 100    | -0.00499  | 0.0605 |\n",
      "| params/nets_4/input_layer/bias              | (100,)     | 100    | -0.0867   | 0.588  |\n",
      "| params/nets_4/input_layer/kernel            | (1, 100)   | 100    | -0.0351   | 0.561  |\n",
      "| params/nets_4/layer_0/BatchNorm_0/bias      | (100,)     | 100    | 0.0       | 0.0    |\n",
      "| params/nets_4/layer_0/BatchNorm_0/scale     | (100,)     | 100    | 1.0       | 0.0    |\n",
      "| params/nets_4/layer_0/Dense_0/bias          | (100,)     | 100    | 0.00748   | 0.558  |\n",
      "| params/nets_4/layer_0/Dense_0/kernel        | (100, 100) | 10,000 | -0.000229 | 0.0577 |\n",
      "| params/nets_4/layer_1/BatchNorm_0/bias      | (100,)     | 100    | 0.0       | 0.0    |\n",
      "| params/nets_4/layer_1/BatchNorm_0/scale     | (100,)     | 100    | 1.0       | 0.0    |\n",
      "| params/nets_4/layer_1/Dense_0/bias          | (100,)     | 100    | 0.0202    | 0.61   |\n",
      "| params/nets_4/layer_1/Dense_0/kernel        | (100, 100) | 10,000 | -0.000423 | 0.0581 |\n",
      "| params/nets_4/output_layer/bias             | (1,)       | 1      | -0.94     | 0.0    |\n",
      "| params/nets_4/output_layer/kernel           | (100, 1)   | 100    | 0.00162   | 0.0629 |\n",
      "| params/weights                              | (5,)       | 5      | 1.0       | 0.0    |\n",
      "+---------------------------------------------+------------+--------+-----------+--------+\n",
      "Total: 106,511\n"
     ]
    }
   ],
   "source": [
    "setup_rng, rng = random.split(rng)\n",
    "init_x = train_dataset[0][0]\n",
    "init_y = train_dataset[0][1]\n",
    "\n",
    "model, state = setup_training(config, setup_rng, init_x, init_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-07 14:44:23.337920: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-07 14:44:23.865626: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64\n",
      "2022-10-07 14:44:23.865694: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.8/lib64\n",
      "2022-10-07 14:44:23.865701: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/metod/Desktop/PhD/year1/PoE/anytime-poe/experiments/notebooks/wandb/run-20221007_144422-rus88d31</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/metodj/anytime-poe/runs/rus88d31\" target=\"_blank\">desert-cherry-5</a></strong> to <a href=\"https://wandb.ai/metodj/anytime-poe\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.024840831756591797,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 57,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 50,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eeff078d14b4a5e975ae7816c0293b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1 - train loss: 1.45768, val loss: 1.38024, train err: 1.0775, val err: 0.9226, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:   2 - train loss: 1.37613, val loss: 1.35193, train err: 0.9144, val err: 0.8660, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:   3 - train loss: 1.30279, val loss: 1.32709, train err: 0.7677, val err: 0.8164, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:   4 - train loss: 1.24579, val loss: 1.30444, train err: 0.6539, val err: 0.7714, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:   5 - train loss: 1.19725, val loss: 1.28225, train err: 0.5576, val err: 0.7276, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:   6 - train loss: 1.16232, val loss: 1.26001, train err: 0.4890, val err: 0.6841, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:   7 - train loss: 1.13692, val loss: 1.23529, train err: 0.4399, val err: 0.6361, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:   8 - train loss: 1.12147, val loss: 1.20826, train err: 0.4112, val err: 0.5840, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:   9 - train loss: 1.10881, val loss: 1.18108, train err: 0.3885, val err: 0.5322, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  10 - train loss: 1.09801, val loss: 1.15599, train err: 0.3697, val err: 0.4851, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  11 - train loss: 1.08760, val loss: 1.13250, train err: 0.3521, val err: 0.4416, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  12 - train loss: 1.07953, val loss: 1.11017, train err: 0.3393, val err: 0.4008, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  13 - train loss: 1.07139, val loss: 1.09124, train err: 0.3266, val err: 0.3671, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  14 - train loss: 1.06369, val loss: 1.07591, train err: 0.3150, val err: 0.3407, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  15 - train loss: 1.05630, val loss: 1.06276, train err: 0.3041, val err: 0.3188, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  16 - train loss: 1.04935, val loss: 1.05081, train err: 0.2943, val err: 0.2995, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  17 - train loss: 1.04219, val loss: 1.04009, train err: 0.2842, val err: 0.2827, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  18 - train loss: 1.03644, val loss: 1.03053, train err: 0.2769, val err: 0.2683, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  19 - train loss: 1.03028, val loss: 1.02140, train err: 0.2690, val err: 0.2550, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  20 - train loss: 1.02508, val loss: 1.01337, train err: 0.2630, val err: 0.2438, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  21 - train loss: 1.01993, val loss: 1.00627, train err: 0.2572, val err: 0.2346, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  22 - train loss: 1.01423, val loss: 0.99910, train err: 0.2505, val err: 0.2253, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  23 - train loss: 1.00843, val loss: 0.98823, train err: 0.2436, val err: 0.2094, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  24 - train loss: 1.00209, val loss: 0.98276, train err: 0.2359, val err: 0.2035, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  25 - train loss: 0.99668, val loss: 0.97687, train err: 0.2300, val err: 0.1970, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  26 - train loss: 0.99205, val loss: 0.97051, train err: 0.2256, val err: 0.1897, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  27 - train loss: 0.98739, val loss: 0.96740, train err: 0.2212, val err: 0.1883, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  28 - train loss: 0.98241, val loss: 0.96159, train err: 0.2163, val err: 0.1822, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  29 - train loss: 0.97779, val loss: 0.95688, train err: 0.2121, val err: 0.1781, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  30 - train loss: 0.97260, val loss: 0.94997, train err: 0.2070, val err: 0.1702, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  31 - train loss: 0.96828, val loss: 0.94745, train err: 0.2035, val err: 0.1700, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  32 - train loss: 0.96305, val loss: 0.94406, train err: 0.1984, val err: 0.1684, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  33 - train loss: 0.95804, val loss: 0.93871, train err: 0.1939, val err: 0.1634, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  34 - train loss: 0.95304, val loss: 0.93600, train err: 0.1893, val err: 0.1630, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  35 - train loss: 0.94800, val loss: 0.93187, train err: 0.1848, val err: 0.1603, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  36 - train loss: 0.94306, val loss: 0.92693, train err: 0.1805, val err: 0.1562, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  37 - train loss: 0.93831, val loss: 0.92282, train err: 0.1767, val err: 0.1535, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  38 - train loss: 0.93340, val loss: 0.91813, train err: 0.1726, val err: 0.1500, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  39 - train loss: 0.92866, val loss: 0.91379, train err: 0.1688, val err: 0.1471, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  40 - train loss: 0.92383, val loss: 0.90918, train err: 0.1650, val err: 0.1437, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  41 - train loss: 0.91905, val loss: 0.90435, train err: 0.1613, val err: 0.1401, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  42 - train loss: 0.91511, val loss: 0.90018, train err: 0.1590, val err: 0.1376, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  43 - train loss: 0.90989, val loss: 0.89563, train err: 0.1547, val err: 0.1346, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  44 - train loss: 0.90538, val loss: 0.89162, train err: 0.1516, val err: 0.1324, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  45 - train loss: 0.90080, val loss: 0.88853, train err: 0.1484, val err: 0.1318, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  46 - train loss: 0.89632, val loss: 0.88427, train err: 0.1455, val err: 0.1293, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  47 - train loss: 0.89186, val loss: 0.87884, train err: 0.1426, val err: 0.1250, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  48 - train loss: 0.88738, val loss: 0.87528, train err: 0.1397, val err: 0.1237, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  49 - train loss: 0.88263, val loss: 0.87072, train err: 0.1365, val err: 0.1209, lr: 0.00010\n",
      "Best val_err\n",
      "epoch:  50 - train loss: 0.87810, val loss: 0.86577, train err: 0.1336, val err: 0.1175, lr: 0.00010\n",
      "Best val_err\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/err</td><td>█▇▆▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▇▆▅▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val/err</td><td>██▇▇▆▆▅▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val/loss</td><td>██▇▇▆▆▆▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>50</td></tr><tr><td>best_val_err</td><td>0.1175</td></tr><tr><td>epoch</td><td>50</td></tr><tr><td>learning_rate</td><td>0.0001</td></tr><tr><td>train/err</td><td>0.13362</td></tr><tr><td>train/loss</td><td>0.8781</td></tr><tr><td>val/err</td><td>0.1175</td></tr><tr><td>val/loss</td><td>0.86577</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">desert-cherry-5</strong>: <a href=\"https://wandb.ai/metodj/anytime-poe/runs/rus88d31\" target=\"_blank\">https://wandb.ai/metodj/anytime-poe/runs/rus88d31</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221007_144422-rus88d31/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "state = train_loop(\n",
    "    model, state, config, rng, make_loss, make_loss, train_loader, val_loader,\n",
    "    # test_loader,\n",
    "    wandb_kwargs={\n",
    "        'mode': 'online',\n",
    "        # 'notes': '',\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f1c3e72c33e9d599052a4f04c6971142100cc706e19ec52aa01eeb819b5a8e9"
  },
  "kernelspec": {
   "display_name": "any-poe",
   "language": "python",
   "name": "any-poe"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
